#!/usr/bin/env python
# coding=utf-8

import os
import sys
import json
import logging
import random
import time
import glob
from typing import Any, Dict, List, Tuple, Optional, Union
import numpy as np
import tensorflow as tf
from tqdm import tqdm
import gin
from absl import app, flags
import jax
from jax import numpy as jnp
import flax
from flax.training import train_state
from flax.training import checkpoints as tcheckpoints
from flax import jax_utils
import optax
from functools import partial
import sentencepiece as spm
import types
from flax.core import FrozenDict
import jax.tree_util as tree_util

def load_flax_ckpt(ckpt_path, vocab_size):
    state = tcheckpoints.restore_checkpoint(ckpt_path, None)
    if not state or 'optimizer' not in state or 'target' not in state['optimizer']:
        raise ValueError("æ— æ³•åœ¨checkpointä¸­æ‰¾åˆ°å‚æ•°ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼")
    params = state['optimizer']['target']
    # æˆªå–embeddingä»¥é€‚é…æ–°è¯è¡¨
    if params['decoder']['embed']['embedding'].shape[0] != vocab_size:
        params['decoder']['embed']['embedding'] = params['decoder']['embed']['embedding'][:vocab_size, :]
    return params

def save_flax_ckpt(save_dir, step, params, model_state, opt_state):
    state_dict = {
        'optimizer': {
            'target': params,
            'state': opt_state
        },
        'state': model_state
    }
    tcheckpoints.save_checkpoint(
        ckpt_dir=save_dir,
        target=state_dict,
        step=step,
        overwrite=True
    )

# åº”ç”¨è¡¥ä¸
# æ·»åŠ  KeyArray ç±»å‹
jax.random.KeyArray = jax.Array
jax.clear_caches()

def recursive_frozendict(d):
    if isinstance(d, dict):
        return FrozenDict({k: recursive_frozendict(v) for k, v in d.items()})
    return d

class OptimizerDef:
    \"\"\"å®Œæ•´çš„OptimizerDefå®ç°\"\"\"
    def __init__(self, optax_optimizer: optax.GradientTransformation):
        self.optax_optimizer = optax_optimizer
        
    def create(self, target):
        return Optimizer(self.optax_optimizer, target)
    
    def init_state(self, target):
        return self.optax_optimizer.init(target)

class Optimizer:
    \"\"\"å®Œæ•´çš„Optimizerå®ç°\"\"\"
    def __init__(self, optax_optimizer: optax.GradientTransformation, target):
        self.optimizer_def = OptimizerDef(optax_optimizer)
        self.target = target
        self.state = optax_optimizer.init(target)
        self.step = 0
    
    def apply_gradient(self, grads, **kwargs):
        updates, new_state = self.optimizer_def.optax_optimizer.update(
            grads, self.state, self.target
        )
        new_target = optax.apply_updates(self.target, updates)
        
        new_optimizer = Optimizer(self.optimizer_def.optax_optimizer, new_target)
        new_optimizer.state = new_state
        new_optimizer.step = self.step + 1
        return new_optimizer

def Adam(learning_rate=0.001, beta1=0.9, beta2=0.999, eps=1e-8, weight_decay=0.0):
    \"\"\"è¿”å›OptimizerDefå®ä¾‹\"\"\"
    if weight_decay > 0:
        return OptimizerDef(optax.adamw(
            learning_rate=learning_rate, 
            b1=beta1, 
            b2=beta2, 
            eps=eps,
            weight_decay=weight_decay
        ))
    else:
        return OptimizerDef(optax.adam(
            learning_rate=learning_rate, 
            b1=beta1, 
            b2=beta2, 
            eps=eps
        ))

# åˆ›å»º flax.optim æ¨¡å—
flax.optim = types.ModuleType('optim')
flax.optim.Optimizer = Optimizer
flax.optim.OptimizerDef = OptimizerDef
flax.optim.GradientTransformation = optax.GradientTransformation
flax.optim.Adam = Adam
flax.optim.AdamW = optax.adamw
flax.optim.Momentum = optax.sgd
flax.optim.RMSProp = optax.rmsprop
sys.modules['flax.optim'] = flax.optim

# ä¿®å¤å¯¼å…¥
sys.modules['flax.optim'] = flax.optim

# è®¾ç½®è·¯å¾„
AG4MDIR = '/kaggle/working/ag4masses'
AGLIB = '/kaggle/working/aglib'
AGDIR = f"{AG4MDIR}/alphageometry"
MELIAD_PATH = f"{AGLIB}/meliad"
DATA = f"{AGLIB}/ag_ckpt_vocab"
TESTDIR = f"/kaggle/working/ag4mtest"
DPO_DIR = f"/kaggle/working/dpo_training"

# ç¡®ä¿ç›®å½•å­˜åœ¨
os.makedirs(TESTDIR, exist_ok=True)
os.makedirs(DPO_DIR, exist_ok=True)

# æ·»åŠ  meliad åˆ° Python è·¯å¾„
sys.path.append(MELIAD_PATH)
sys.path.append(f"{MELIAD_PATH}/transformer")

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

FLAGS = flags.FLAGS

# é…ç½®å‚æ•°
flags.DEFINE_string('gin_search_paths', f'{MELIAD_PATH}/transformer/configs', 'Giné…ç½®æ–‡ä»¶è·¯å¾„')
flags.DEFINE_multi_string('gin_file', ['base_htrans.gin'], 'Giné…ç½®æ–‡ä»¶åˆ—è¡¨')
flags.DEFINE_multi_string('gin_param', None, 'Ginå‚æ•°ç»‘å®š')
flags.DEFINE_string('ckpt_path', f'{DATA}/checkpoint_10999999', 'åˆå§‹æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„')
flags.DEFINE_string('vocab_path', f'{DATA}/geometry.757.model', 'è¯æ±‡è¡¨æ–‡ä»¶è·¯å¾„')
flags.DEFINE_string('train_data', f'/kaggle/working/ag4mtest/butterfly_dpo_data.jsonl', 'è®­ç»ƒæ•°æ®è·¯å¾„')
flags.DEFINE_string('output_dir', f'{DPO_DIR}/checkpoints', 'è¾“å‡ºç›®å½•')
flags.DEFINE_float('beta', 0.1, 'DPOæ¸©åº¦å‚æ•°')
flags.DEFINE_float('learning_rate', 1e-3, 'å­¦ä¹ ç‡')
flags.DEFINE_integer('batch_size', 4, 'æ‰¹å¤§å°')
flags.DEFINE_integer('max_seq_length', 512, 'æœ€å¤§åºåˆ—é•¿åº¦')
flags.DEFINE_integer('num_epochs', 30, 'è®­ç»ƒè½®æ•°')
flags.DEFINE_integer('steps_per_epoch', 100, 'æ¯è½®æ­¥æ•°')
flags.DEFINE_integer('save_steps', 100, 'ä¿å­˜é—´éš”æ­¥æ•°')
flags.DEFINE_bool('use_amp', True, 'å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')


# å®šä¹‰TransformerTaskConfigç±»
@gin.configurable
class TransformerTaskConfig:
    \"\"\"Transformerä»»åŠ¡é…ç½®\"\"\"
    def __init__(
        self, 
        vocab_size: int, 
        sequence_length: int, 
        batch_size: int, 
        max_sequence_length: int
    ):
        self.vocab_size = vocab_size
        self.sequence_length = sequence_length
        self.batch_size = batch_size
        self.max_sequence_length = max_sequence_length

class CustomTrainState:
    \"\"\"è‡ªå®šä¹‰è®­ç»ƒçŠ¶æ€ç»“æ„\"\"\"
    def __init__(self, step, params, model_state, optimizer_state):
        self.step = step
        self.params = params
        self.model_state = model_state
        self.optimizer_state = optimizer_state

class DPOTrainer:
    def __init__(
        self,
        model_path: str,
        vocab_path: str,
        beta: float = 0.1,
        learning_rate: float = 1e-3,
        batch_size: int = 4,
        max_seq_length: int = 512,
        use_amp: bool = True
    ):
        # å‡å°‘JAXè¾“å‡º
        jax.config.update('jax_debug_nans', True)
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
        tf.get_logger().setLevel('ERROR')
        
        # é…ç½®æ—¥å¿—
        self._configure_logging()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.vocab = self._create_sentencepiece_vocab(vocab_path)
        self._init_gin_config(model_path)
        self.task_config = self._create_task_config()
        self.model = self._init_model()
        self.tstate = self._init_training_state(model_path)
        self.initialized_state = False
        self.model_state = {}
        
        # åˆ›å»ºè®­ç»ƒä»»åŠ¡
        from transformer import inference_utils
        self.task = inference_utils.training_loop.Trainer(
            get_training_dataset_iterator=lambda: None,
            get_test_dataset_iterator=None,
            pretty_print_input_function=None,
            process_summaries_function=inference_utils.models.process_summaries_function(self.vocab),
            load_dir=model_path,
            workdir='',
            replicate_mode=False
        ).create_training_task('train', self.model, jax.random.PRNGKey(0), {})
        
        # é…ç½®è®­ç»ƒå‚æ•°
        self.beta = beta
        self.batch_size = batch_size
        self.max_seq_length = max_seq_length
        self.global_step = 0
        self.optimizer = self._create_optimizer(learning_rate)
        self.use_amp = use_amp
        self.learning_rate = learning_rate
            
    def _configure_logging(self):
        \"\"\"é…ç½®æ—¥å¿—è¾“å‡ºçº§åˆ«\"\"\"
        # è®¾ç½®åŸºæœ¬æ—¥å¿—çº§åˆ«ä¸ºWARNING
        logging.getLogger().setLevel(logging.WARNING)
        logging.getLogger('jax').setLevel(logging.WARNING)
        logging.getLogger('flax').setLevel(logging.WARNING)
        logging.getLogger('tensorflow').setLevel(logging.WARNING)
        
        # é…ç½®æ§åˆ¶å°è¾“å‡º
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.WARNING)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(formatter)
        logging.getLogger().addHandler(console_handler)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # è®¾ç½®ä¸º2ä»¥å‡å°‘TensorFlowè¾“å‡º
        os.environ['JAX_ENABLE_X64'] = '0'
        os.environ['JAX_DISABLE_JIT'] = '0'
        
        # ç¦ç”¨JAXçš„è°ƒè¯•è¾“å‡º
        jax.config.update('jax_debug_nans', False)
        jax.config.update('jax_log_compiles', False)
    
    def _create_sentencepiece_vocab(self, model_path: str):
        \"\"\"åˆ›å»ºSentencePieceè¯æ±‡è¡¨\"\"\"
        class CustomSPVocabulary:
            def __init__(self, model_path):
                self.sp = spm.SentencePieceProcessor()
                self.sp.Load(model_path)
                self.vocab_size = self.sp.GetPieceSize()
            
            def encode(self, text: str) -> List[int]:
                return self.sp.EncodeAsIds(text)
            
            def decode(self, ids: List[int]) -> str:
                return self.sp.DecodeIds(ids)
        
        return CustomSPVocabulary(model_path)
        
    def _init_gin_config(self, model_path: str):
        \"\"\"åˆå§‹åŒ–Giné…ç½®\"\"\"
        # é…ç½®Ginæœç´¢è·¯å¾„
        config_dir = f'{MELIAD_PATH}/transformer/configs'
        logger.info(f"é…ç½®æ–‡ä»¶ç›®å½•: {config_dir}")
        
        if os.path.exists(config_dir):
            logger.info(f"é…ç½®æ–‡ä»¶ç›®å½•å†…å®¹: {os.listdir(config_dir)}")
        
        # æ·»åŠ  meliad åˆ° Python è·¯å¾„
        if MELIAD_PATH not in sys.path:
            sys.path.append(MELIAD_PATH)
        if f"{MELIAD_PATH}/transformer" not in sys.path:
            sys.path.append(f"{MELIAD_PATH}/transformer")
        
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        from transformer import nn_components
        from transformer import models
        from transformer import transformer_layer
        from transformer import attention
        from transformer import transformer_base
        
        # æ‰“å°æ¨¡å—å†…å®¹ä»¥æ£€æŸ¥å¯ç”¨çš„ç»„ä»¶
        logger.info("nn_components æ¨¡å—å†…å®¹:")
        for name in dir(nn_components):
            if not name.startswith('_'):
                logger.info(f"  - {name}")
        
        # åˆ›å»º transformer æ¨¡å—
        transformer = types.ModuleType('transformer')
        transformer.nn_components = nn_components
        transformer.models = models
        transformer.transformer_layer = transformer_layer
        transformer.attention = attention
        transformer.transformer_base = transformer_base
        
        # æ³¨å†Œæ¨¡å—
        gin.configurable(transformer)
        logger.info("æ³¨å†Œæ¨¡å—: transformer")
        gin.configurable(transformer.nn_components)
        logger.info("æ³¨å†Œæ¨¡å—: transformer.nn_components")
        
        # æ³¨å†Œå¯é…ç½®é¡¹ï¼ˆåªæ³¨å†Œå®é™…å­˜åœ¨çš„ç»„ä»¶ï¼‰
        available_components = {
            'LayerNorm': getattr(nn_components, 'LayerNorm', None),
            'MLP': getattr(nn_components, 'MLP', None),
            'dropout_multiplier_mask': getattr(nn_components, 'dropout_multiplier_mask', None),
            'get_activation_function': getattr(nn_components, 'get_activation_function', None),
            'safe_softmax': getattr(nn_components, 'safe_softmax', None),
            'scalar_initializer': getattr(nn_components, 'scalar_initializer', None),
            'soft_abs': getattr(nn_components, 'soft_abs', None),
            'swish': getattr(nn_components, 'swish', None),
            'tiled_dropout': getattr(nn_components, 'tiled_dropout', None)
        }
        
        for name, component in available_components.items():
            if component is not None:
                logger.info(f"æ³¨å†Œç»„ä»¶: {name}")
                gin.configurable(component)
            else:
                logger.warning(f"ç»„ä»¶ä¸å­˜åœ¨: {name}")
        
        # æ³¨å†Œå…¶ä»–æ¨¡å—ä¸­çš„ç»„ä»¶
        try:
            from transformer.transformer_layer import TransformerLayer
            gin.configurable(TransformerLayer)
            logger.info("æ³¨å†Œç»„ä»¶: TransformerLayer")
        except ImportError:
            logger.warning("æ— æ³•å¯¼å…¥ TransformerLayer")
        
        
        try:
            from transformer.transformer_base import Config
            gin.configurable(Config)
            logger.info("æ³¨å†Œç»„ä»¶: Config")
        except ImportError:
            logger.warning("æ— æ³•å¯¼å…¥ Config")
        
        gin.add_config_file_search_path(config_dir)
        
        # é…ç½®è¦åŠ è½½çš„æ–‡ä»¶
        config_files = [
            'base_htrans.gin',
            'size/medium_150M.gin',
            'options/positions_t5.gin',
            'trainer_configuration.gin'
        ]
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        existing_files = []
        for f in config_files:
            full_path = os.path.join(config_dir, f)
            if os.path.exists(full_path):
                existing_files.append(full_path)
                logger.info(f"æ‰¾åˆ°é…ç½®æ–‡ä»¶: {full_path}")

            else:
                logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
                # æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦å­˜åœ¨
                parent_dir = os.path.dirname(full_path)
                if os.path.exists(parent_dir):
                    logger.info(f"çˆ¶ç›®å½• {parent_dir} å­˜åœ¨ï¼Œå†…å®¹: {os.listdir(parent_dir)}")
                else:
                    logger.warning(f"çˆ¶ç›®å½• {parent_dir} ä¸å­˜åœ¨")
        
        # æ·»åŠ ç”¨æˆ·æŒ‡å®šçš„æ–‡ä»¶
        if FLAGS.gin_file:
            for f in FLAGS.gin_file:
                full_path = os.path.join(config_dir, f)
                if os.path.exists(full_path):
                    existing_files.append(full_path)
                    logger.info(f"æ‰¾åˆ°ç”¨æˆ·æŒ‡å®šé…ç½®æ–‡ä»¶: {full_path}")
                else:
                    logger.warning(f"ç”¨æˆ·æŒ‡å®šé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
        
        if not existing_files:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„é…ç½®æ–‡ä»¶")
        
        # è®°å½•é…ç½®
        logger.info(f"åŠ è½½Giné…ç½®æ–‡ä»¶: {', '.join(existing_files)}")
        
        # ä¿®æ”¹ gin é…ç½®ä»¥é€‚é…æ–°ç‰ˆæœ¬
        # åˆ›å»ºä¸€ä¸ª lambda å‡½æ•°ä½œä¸ºéšæœºæ•°ç”Ÿæˆå™¨
        def make_rng():
            return jax.random.PRNGKey(0)
        
        # æ³¨å†Œéšæœºæ•°ç”Ÿæˆå™¨
        gin.bind_parameter('transformer.nn_components.tiled_dropout.rng_function', make_rng)
        
        # è§£æé…ç½®
        try:
            # ä½¿ç”¨ç»å¯¹è·¯å¾„è§£æé…ç½®
            gin.parse_config_files_and_bindings(
                existing_files, 
                FLAGS.gin_param,
                skip_unknown=True  # è·³è¿‡æœªçŸ¥çš„é…ç½®é¡¹
            )
        except Exception as e:
            logger.error(f"Giné…ç½®é”™è¯¯: {str(e)}")
            raise
    
    def _create_task_config(self) -> TransformerTaskConfig:
        \"\"\"åˆ›å»ºä»»åŠ¡é…ç½®\"\"\"
        return TransformerTaskConfig(
            vocab_size=self.vocab.vocab_size,
            sequence_length=512,
            batch_size=FLAGS.batch_size,
            max_sequence_length=512
        )
    
    def _init_model(self):
        \"\"\"åˆå§‹åŒ–æ¨¡å‹\"\"\"
        from transformer.models import DecoderOnlyLanguageModel
        
        # é™ä½åˆå§‹åŒ–æœŸé—´çš„æ—¥å¿—çº§åˆ«
        orig_level = logging.getLogger().level
        logging.getLogger().setLevel(logging.ERROR)
        
        try:
            actual_vocab_size = self.vocab.vocab_size
            original_vocab_size = self.task_config.vocab_size
            self.task_config.vocab_size = actual_vocab_size
            
            print(f"ä¿®å¤è¯æ±‡è¡¨å¤§å°: {original_vocab_size} â†’ {actual_vocab_size}")
            model = DecoderOnlyLanguageModel(
                mode="train", 
                task_config=self.task_config
            )

            self.task_config.vocab_size = original_vocab_size
            logger.info("æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            print(f"  æ¨¡å‹æ¨¡å¼: {getattr(model, 'mode', 'unknown')}")
            
            logger.info("æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼ˆå»¶è¿Ÿå‚æ•°åˆå§‹åŒ–ï¼‰")
            return model
            
        finally:
            logging.getLogger().setLevel(orig_level)
            
    
    def _create_optimizer(self, learning_rate: float) -> optax.GradientTransformation:
        \"\"\"åˆ›å»ºä¼˜åŒ–å™¨\"\"\"
        print(f" åˆ›å»ºä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡: {learning_rate}")
    
        optimizer = optax.chain(
            optax.clip_by_global_norm(1.0),
            optax.adam(learning_rate=learning_rate)
        )
        
        
        return optimizer

    
    def _dpo_loss(self, params: Dict[str, Any], chosen_data: Tuple[jnp.ndarray, jnp.ndarray],
             rejected_data: Tuple[jnp.ndarray, jnp.ndarray]) -> jnp.ndarray:
        \"\"\"è®¡ç®—DPOæŸå¤± - ä½¿ç”¨jax.debug.printè¿›è¡Œè°ƒè¯•\"\"\"
        chosen_inputs, chosen_targets, chosen_loss_mask = chosen_data
        rejected_inputs, rejected_targets, rejected_loss_mask = rejected_data
    
        # åˆ›å»ºä¸´æ—¶è®­ç»ƒçŠ¶æ€
        temp_tstate = self.tstate.replace(params=params)
        
        try:
            # è®¡ç®—å½“å‰ç­–ç•¥çš„å¯¹æ•°æ¦‚ç‡
            policy_chosen_logps = self._compute_log_probs_pure(temp_tstate, chosen_inputs, chosen_targets)
            policy_rejected_logps = self._compute_log_probs_pure(temp_tstate, rejected_inputs, rejected_targets)
            
            if hasattr(self, 'reference_params') and self.reference_params is not None:
                ref_tstate = self.tstate.replace(params=self.reference_params)
                reference_chosen_logps = self._compute_log_probs_pure(ref_tstate, chosen_inputs, chosen_targets)
                reference_rejected_logps = self._compute_log_probs_pure(ref_tstate, rejected_inputs, rejected_targets)
            else:
                # ğŸ”§ å¦‚æœçœŸçš„æ²¡æœ‰å‚è€ƒç­–ç•¥ï¼Œä½¿ç”¨å¸¦å™ªå£°çš„ç‰ˆæœ¬
                print("è­¦å‘Šï¼šæ²¡æœ‰å‚è€ƒç­–ç•¥ï¼Œä½¿ç”¨å™ªå£°ç‰ˆæœ¬")
                noise_key1, noise_key2 = jax.random.split(jax.random.PRNGKey(42))
                reference_chosen_logps = policy_chosen_logps + jax.random.normal(noise_key1, policy_chosen_logps.shape) * 0.1
                reference_rejected_logps = policy_rejected_logps + jax.random.normal(noise_key2, policy_rejected_logps.shape) * 0.1
                
            
            # ä½¿ç”¨ä¼ å…¥çš„æ©ç è®¡ç®—å¹³å‡å¯¹æ•°æ¦‚ç‡
            # å½“å‰ç­–ç•¥çš„å¹³å‡å¯¹æ•°æ¦‚ç‡
            policy_chosen_sum = jnp.sum(policy_chosen_logps * chosen_loss_mask, axis=-1)
            policy_chosen_lengths = jnp.sum(chosen_loss_mask, axis=-1) + 1e-8
            policy_chosen_mean = policy_chosen_sum / policy_chosen_lengths
            
            policy_rejected_sum = jnp.sum(policy_rejected_logps * rejected_loss_mask, axis=-1)
            policy_rejected_lengths = jnp.sum(rejected_loss_mask, axis=-1) + 1e-8
            policy_rejected_mean = policy_rejected_sum / policy_rejected_lengths
            
            # å‚è€ƒç­–ç•¥çš„å¹³å‡å¯¹æ•°æ¦‚ç‡
            ref_chosen_sum = jnp.sum(reference_chosen_logps * chosen_loss_mask, axis=-1)
            ref_chosen_mean = ref_chosen_sum / policy_chosen_lengths
            
            ref_rejected_sum = jnp.sum(reference_rejected_logps * rejected_loss_mask, axis=-1)
            ref_rejected_mean = ref_rejected_sum / policy_rejected_lengths
            
            # è®¡ç®—ç­–ç•¥ä¼˜åŠ¿ï¼ˆæ ‡å‡†DPOå…¬å¼ï¼‰
            policy_logratios = policy_chosen_mean - policy_rejected_mean
            reference_logratios = ref_chosen_mean - ref_rejected_mean
            logits = policy_logratios - reference_logratios
                    
            embedding_params = params['decoder']['embed']['embedding']
            regularization = 1e-8 * jnp.sum(embedding_params ** 2)  # L2æ­£åˆ™åŒ–
            logits = logits + regularization
            
            # åº”ç”¨æ¸©åº¦å‚æ•°
            logits = self.beta * logits
            logits = jnp.clip(logits, -100, 100)
            
            # æ ‡å‡†DPOæŸå¤±ï¼ˆå¸¦æ ‡ç­¾å¹³æ»‘ï¼‰
            label_smoothing = 0.1  # å¯é…ç½®çš„æ ‡ç­¾å¹³æ»‘å‚æ•°
            losses = (
                -jax.nn.log_sigmoid(logits) * (1 - label_smoothing)
                - jax.nn.log_sigmoid(-logits) * label_smoothing
            )
            
            losses = jnp.clip(losses, 0.0, 100)
            
            # è°ƒè¯•ä¿¡æ¯
            if self.global_step % 10 == 0:
                jax.debug.print("DPOè°ƒè¯•: policy_chosen={:.4f}, policy_rejected={:.4f}, ref_chosen={:.4f}, ref_rejected={:.4f}, logits={:.4f}, loss={:.4f}", 
                               jnp.mean(policy_chosen_mean), jnp.mean(policy_rejected_mean),
                               jnp.mean(ref_chosen_mean), jnp.mean(ref_rejected_mean),
                               jnp.mean(logits), jnp.mean(losses))
                # æ£€æŸ¥å‚æ•°å·®å¼‚
                if hasattr(self, 'reference_params'):
                    param_diff = jnp.mean(jnp.abs(params['decoder']['embed']['embedding'] - 
                                                self.reference_params['decoder']['embed']['embedding']))
                    jax.debug.print("å‚æ•°å·®å¼‚: {:.6f}", param_diff)
                    
                    # æ£€æŸ¥logitsçš„åŸå§‹å€¼ï¼ˆæœªè£å‰ªï¼‰
                    raw_logits = policy_logratios - reference_logratios
                    jax.debug.print("åŸå§‹logits: {:.4f}, è£å‰ªålogits: {:.4f}", 
                                   jnp.mean(raw_logits), jnp.mean(logits))
            
            return jnp.mean(losses)
            
        except Exception as e:
            print(f"DPOæŸå¤±è®¡ç®—å¤±è´¥: {e}")
            return jnp.array(1.0, dtype=jnp.float32)
            
                
    def _compute_log_probs_pure(self, tstate, inputs: dict, targets: jnp.ndarray) -> jnp.ndarray:
        batch_size, seq_len = targets.shape
    
        try:
            complete_inputs = dict(inputs)
            if 'epoch' not in complete_inputs:
                complete_inputs['epoch'] = jnp.ones((batch_size,), dtype=jnp.int32)
            if 'loss_mask' not in complete_inputs:
                complete_inputs['loss_mask'] = jnp.ones((batch_size, seq_len), dtype=jnp.bool_)
    
            # æ„å»ºvariableså­—å…¸
            params = tstate.params
            if not isinstance(params, FrozenDict):
                params = FrozenDict(params)
            
            variables = {'params': params}
            
            state_key = f"{batch_size}x{seq_len}"
            
            if not hasattr(self, 'model_states'):
                self.model_states = {}
            
            # åŠ¨æ€åˆå§‹åŒ–çŠ¶æ€
            if state_key not in self.model_states:
                if self.global_step % 50 == 0:
                    print(f"ä¸º {state_key} åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€...")
                
                original_batch_size = self.task_config.batch_size
                original_seq_length = self.task_config.sequence_length
                
                try:
                    self.task_config.batch_size = batch_size
                    self.task_config.sequence_length = seq_len
                    
                    init_rng = jax.random.PRNGKey(42)
                    init_rngs = {'params': init_rng, 'dropout': init_rng}
                    init_variables = self.model.init(init_rngs, complete_inputs)
                    
                    # ä¿å­˜
                    self.model_states[state_key] = {k: v for k, v in init_variables.items() if k != 'params'}
                    
                finally:
                    self.task_config.batch_size = original_batch_size
                    self.task_config.sequence_length = original_seq_length
            
            # æ·»åŠ çŠ¶æ€åˆ°variables
            if state_key in self.model_states:
                variables.update(self.model_states[state_key])
            
            # å…è®¸çŠ¶æ€æ›´æ–°
            result = self.model.apply(
                variables,
                complete_inputs,
                method=self.model.predict_logits,
                rngs={'dropout': jax.random.PRNGKey(0)},
                mutable=['state']  # å…è®¸æ›´æ–°stateé›†åˆ
            )
            
            # å¤„ç†è¿”å›ç»“æœ
            if isinstance(result, tuple):
                logits, updated_variables = result
                # æ›´æ–°çŠ¶æ€
                if 'state' in updated_variables:
                    self.model_states[state_key]['state'] = updated_variables['state']
            else:
                logits = result
    
            # è®¡ç®—log_softmax
            log_probs = jax.nn.log_softmax(logits, axis=-1)
    
            # è·å–ç›®æ ‡tokençš„log_probs
            batch_indices = jnp.arange(batch_size)[:, None]
            seq_indices = jnp.arange(seq_len)[None, :]
            valid_targets = jnp.clip(targets, 0, logits.shape[-1] - 1)
            target_log_probs = log_probs[batch_indices, seq_indices, valid_targets]
            return target_log_probs
    
        except Exception as e:
            if self.global_step % 50 == 0:
                print(f"è®¡ç®—å¤±è´¥: {e}")
            return jnp.full((batch_size, seq_len), -3.0, dtype=jnp.float32)
    
    def _update_step(self, chosen_data: Tuple[jnp.ndarray, jnp.ndarray],
                rejected_data: Tuple[jnp.ndarray, jnp.ndarray]):
        \"\"\"æ‰§è¡Œå•ä¸ªæ›´æ–°æ­¥éª¤\"\"\"

        from flax.core import FrozenDict

        def set_in_frozendict(fd, keys, value):
            \"\"\"é€’å½’åœ°åœ¨FrozenDictä¸­è®¾ç½®å€¼ï¼Œè¿”å›æ–°çš„FrozenDictã€‚\"\"\"
            if len(keys) == 1:
                d = dict(fd)
                d[keys[0]] = value
                return FrozenDict(d)
            else:
                d = dict(fd)
                d[keys[0]] = set_in_frozendict(d[keys[0]], keys[1:], value)
                return FrozenDict(d)

        def loss_fn(params):
            return self._dpo_loss(params, chosen_data, rejected_data)

        try:

            # è®¡ç®—æ¢¯åº¦
            loss, grads = jax.value_and_grad(loss_fn)(self.tstate.params)

            # æ£€æŸ¥æ¢¯åº¦
            grad_norm = jax.tree_util.tree_reduce(
                lambda x, y: x + jnp.sum(jnp.square(y)),
                grads,
                initializer=0.0
            )
            grad_norm = jnp.sqrt(grad_norm)

            if self.global_step % 5 == 0:  # æ›´é¢‘ç¹çš„æ£€æŸ¥
                # æ£€æŸ¥embeddingæ¢¯åº¦
                if (
                    'decoder' in grads
                    and 'embed' in grads['decoder']
                    and 'embedding' in grads['decoder']['embed']
                ):
                    embed_grad = grads['decoder']['embed']['embedding']
                    embed_grad_norm = jnp.sqrt(jnp.sum(jnp.square(embed_grad)))
                    embed_grad_max = jnp.max(jnp.abs(embed_grad))
                    embed_grad_mean = jnp.mean(jnp.abs(embed_grad))
                    
                    print(f"Step {self.global_step}: embeddingæ¢¯åº¦ - norm={embed_grad_norm:.6f}, max={embed_grad_max:.6f}, mean={embed_grad_mean:.6f}")
                    
                    if jax.device_get(embed_grad_norm) < 1e-8:
                        print("  âš ï¸ è­¦å‘Šï¼šEmbeddingæ¢¯åº¦ä¸ºé›¶ï¼")
                        
                        # æ£€æŸ¥å…¶ä»–å±‚çš„æ¢¯åº¦
                        total_grad_norm = 0
                        for key, value in grads.items():
                            if isinstance(value, dict):
                                for subkey, subvalue in value.items():
                                    if isinstance(subvalue, dict):
                                        for subsubkey, subsubvalue in subvalue.items():
                                            if hasattr(subsubvalue, 'shape'):
                                                sub_grad_norm = jnp.sqrt(jnp.sum(jnp.square(subsubvalue)))
                                                total_grad_norm += sub_grad_norm
                                                if sub_grad_norm > 1e-6:
                                                    print(f"    {key}.{subkey}.{subsubkey} æ¢¯åº¦: {sub_grad_norm:.6f}")
                            elif hasattr(value, 'shape'):
                                sub_grad_norm = jnp.sqrt(jnp.sum(jnp.square(value)))
                                total_grad_norm += sub_grad_norm
                                if sub_grad_norm > 1e-6:
                                    print(f"    {key} æ¢¯åº¦: {sub_grad_norm:.6f}")
                        
                        print(f"    æ€»æ¢¯åº¦èŒƒæ•°: {total_grad_norm:.6f}")
                
                # æ£€æŸ¥å½“å‰å‚æ•°ä¸å‚è€ƒå‚æ•°çš„å·®å¼‚
                if hasattr(self, 'reference_params'):
                    current_params = self.tstate.params
                    ref_params = self.reference_params
                    
                    if 'decoder' in current_params and 'embed' in current_params['decoder']:
                        current_embed = current_params['decoder']['embed']['embedding']
                        ref_embed = ref_params['decoder']['embed']['embedding']
                        
                        # è®¡ç®—å‚æ•°å·®å¼‚
                        param_diff = jnp.mean(jnp.abs(current_embed - ref_embed))
                        param_diff_max = jnp.max(jnp.abs(current_embed - ref_embed))
                        
                        print(f"Step {self.global_step}: å‚æ•°å·®å¼‚ - mean={param_diff:.6f}, max={param_diff_max:.6f}")
                        
                        # å¦‚æœå‚æ•°å·®å¼‚å¾ˆå°ï¼Œå¯èƒ½æ˜¯è®­ç»ƒæœ‰é—®é¢˜
                        if jax.device_get(param_diff) < 1e-6:
                            print("  âš ï¸ è­¦å‘Šï¼šå‚æ•°å‡ ä¹æ²¡æœ‰å˜åŒ–ï¼")
                        
                        # æ£€æŸ¥å­¦ä¹ ç‡
                        if hasattr(self.tstate, 'opt_state'):
                            print(f"Step {self.global_step}: å­¦ä¹ ç‡çŠ¶æ€å­˜åœ¨")

            # æ¢¯åº¦è£å‰ª - é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            max_grad_norm = 1.0
            if grad_norm > max_grad_norm:
                grads = jax.tree_util.tree_map(
                    lambda g: g * max_grad_norm / grad_norm, grads
                )
                print(f"Step {self.global_step}: æ¢¯åº¦è£å‰ª - ä» {grad_norm:.4f} åˆ° {max_grad_norm}")

            # æ›´æ–°å‚æ•°ï¼ˆå³ä½¿æ¢¯åº¦å¾ˆå°ä¹Ÿæ›´æ–°ï¼‰
            updates, new_opt_state = self.tstate.tx.update(
                grads, self.tstate.opt_state, self.tstate.params
            )
            new_params = optax.apply_updates(self.tstate.params, updates)
            if not isinstance(new_params, FrozenDict):
                new_params = FrozenDict(new_params)
            # æ›´æ–°è®­ç»ƒçŠ¶æ€
            self.tstate = self.tstate.replace(
                step=self.tstate.step + 1,
                params=new_params,
                opt_state=new_opt_state
            )

            self.global_step += 1
            return jax.device_get(loss)

        except Exception as e:
            logger.error(f"æ›´æ–°æ­¥éª¤å¤±è´¥: {str(e)}")
            import traceback
            logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            raise
    

    def _init_training_state(self, model_path: str) -> Any:
        \"\"\"åˆå§‹åŒ–è®­ç»ƒçŠ¶æ€ - ä¿®å¤æ‰€æœ‰é…ç½®ä¸€è‡´æ€§\"\"\"
        def recursive_frozendict(d):
            if isinstance(d, dict):
                return FrozenDict({k: recursive_frozendict(v) for k, v in d.items()})
            elif isinstance(d, (list, tuple)):
                return type(d)(recursive_frozendict(item) for item in d)
            else:
                return d
                
        try:
            print(" å»¶è¿Ÿåˆå§‹åŒ–æ¨¡å‹å‚æ•°...")
            
            #  ä¸´æ—¶ä¿®æ”¹task_configä»¥åŒ¹é…å®é™…è¯æ±‡è¡¨å¤§å°
            original_batch_size = self.task_config.batch_size
            original_seq_length = self.task_config.sequence_length
            original_max_seq_length = self.task_config.max_sequence_length
            original_vocab_size = self.task_config.vocab_size
            
            # ä½¿ç”¨å®é™…çš„è¯æ±‡è¡¨å¤§å°
            actual_vocab_size = self.vocab.vocab_size
            
            # ä½¿ç”¨æ›´å°çš„é…ç½®ï¼Œå¹¶ç¡®ä¿ä¸€è‡´æ€§
            self.task_config.batch_size = 1
            self.task_config.sequence_length = 128  # ä½¿ç”¨16
            self.task_config.max_sequence_length = 128  # ä½¿ç”¨16
            self.task_config.vocab_size = actual_vocab_size
            
            try:
                # é‡æ–°åˆå§‹åŒ–æ¨¡å‹ä»¥ä½¿ç”¨æ–°çš„é…ç½®
                from transformer.models import DecoderOnlyLanguageModel
                temp_model = DecoderOnlyLanguageModel(
                    mode="train", 
                    task_config=self.task_config
                )
                
                # åˆå§‹åŒ–æ¨¡å‹å‚æ•°
                rng = jax.random.PRNGKey(0)
                params_rng, dropout_rng = jax.random.split(rng)
                
                # è·å–å‡è¾“å…¥
                fake_input = temp_model.get_fake_input()  # ä½¿ç”¨temp_modelè€Œä¸æ˜¯self.model
                print(f"  fake_input keys: {fake_input.keys()}")
  
                # åˆå§‹åŒ–å‚æ•°
                print("  æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹å‚æ•°...")
                variables = temp_model.init(
                    {'params': params_rng, 'dropout': dropout_rng},
                    fake_input
                )
                print(f" å‚æ•°åˆå§‹åŒ–æˆåŠŸï¼Œkeys: {variables.keys()}")
                params = variables.get('params', {})
                params = recursive_frozendict(params)

                model_state = {k: v for k, v in variables.items() if k != 'params'}

                # æ›´æ–°æ¨¡å‹å¼•ç”¨
                self.model = temp_model
                
            finally:
                # æ¢å¤åŸå§‹é…ç½®
                self.task_config.batch_size = original_batch_size
                self.task_config.sequence_length = original_seq_length
                self.task_config.max_sequence_length = original_max_seq_length
                self.task_config.vocab_size = original_vocab_size
            
            # åŠ è½½é¢„è®­ç»ƒæƒé‡
            if model_path and os.path.exists(model_path):
                print(f"åŠ è½½é¢„è®­ç»ƒæƒé‡: {model_path}")
                try:
                    # ç”¨Flaxå…¼å®¹æ–¹å¼åŠ è½½å‚è€ƒå‚æ•°
                    reference_params = load_flax_ckpt(model_path, self.vocab.vocab_size)
                    self.reference_params = recursive_frozendict(reference_params)

                    # ç”Ÿæˆcurrent_paramsï¼ˆå¯åŠ æ‰°åŠ¨ï¼‰
                    def add_small_perturbation(params):
                        def perturb_array(x):
                            if hasattr(x, 'shape'):
                                noise = jax.random.normal(jax.random.PRNGKey(42), x.shape) * 1e-5
                                return x + noise
                            return x
                        return jax.tree_util.tree_map(perturb_array, params)
                    current_params = add_small_perturbation(reference_params)
                    current_params = recursive_frozendict(current_params)

                    new_optimizer = self._create_optimizer(FLAGS.learning_rate)

                    # é‡æ–°åˆ›å»ºè®­ç»ƒçŠ¶æ€
                    from flax.training import train_state
                    tstate = train_state.TrainState.create(
                        apply_fn=self.model.apply,
                        params=current_params,
                        tx=new_optimizer
                    )
                    print("  æˆåŠŸé‡æ–°åˆ›å»ºè®­ç»ƒçŠ¶æ€")
                        
                except Exception as e:
                    print(f" æƒé‡åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–: {e}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"  æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                print("  ä½¿ç”¨éšæœºåˆå§‹åŒ–å‚æ•°")
            
            print(" è®­ç»ƒçŠ¶æ€åˆå§‹åŒ–å®Œæˆ")
    
            
            print(f"å‚è€ƒç­–ç•¥å‚æ•°æ•°é‡: {len(jax.tree_leaves(self.reference_params))}")
            print(f"å½“å‰ç­–ç•¥å‚æ•°æ•°é‡: {len(jax.tree_leaves(tstate.params))}")
            print(" ä¿å­˜å‚è€ƒç­–ç•¥å‚æ•°")

            
            def params_equal(params1, params2):
                def compare_arrays(x, y):
                    if hasattr(x, 'shape') and hasattr(y, 'shape'):
                        return jnp.array_equal(x, y)
                    return x == y
                
                return tree_util.tree_reduce(
                    lambda acc, val: acc and val,
                    tree_util.tree_map(compare_arrays, params1, params2),
                    initializer=True
                )
            
            # ä½¿ç”¨æ­£ç¡®çš„æ¯”è¾ƒ
            print(f"æ·±æ‹·è´åæ˜¯å¦ç›¸åŒ: {params_equal(tstate.params, self.reference_params)}")
            
            self.initialized_state = False
            self.model_state = model_state
            return tstate
            
        except Exception as e:
            print(f" è®­ç»ƒçŠ¶æ€åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
        
    def _prepare_batch(self, examples: List[Dict]) -> Tuple[Tuple[Dict, jnp.ndarray, jnp.ndarray], Tuple[Dict, jnp.ndarray, jnp.ndarray]]:
        \"\"\"å‡†å¤‡æ‰¹æ¬¡æ•°æ®ï¼Œå¹¶ä¸ºcompletion-onlyæŸå¤±è®¡ç®—åˆ›å»ºæ©ç \"\"\"
        if not examples:
            raise ValueError("æ‰¹æ¬¡æ•°æ®ä¸ºç©º")
                    
        # åˆå§‹åŒ–å®¹å™¨
        batch_data = {
            'chosen_inputs': [],
            'chosen_targets': [],
            'chosen_loss_mask': [],
            'rejected_inputs': [],
            'rejected_targets': [],
            'rejected_loss_mask': [],
        }
        
        for i, ex in enumerate(examples):
            prompt = ex['prompt']
            chosen_text = ex['chosen']
            rejected_text = ex['rejected']
            
            prompt_tokens = self.vocab.encode(prompt)
            prompt_len = len(prompt_tokens)

            # --- å¤„ç† chosen ---
            chosen_completion_tokens = self.vocab.encode(chosen_text)
            chosen_full_tokens = (prompt_tokens + chosen_completion_tokens)[:self.max_seq_length]
            
            chosen_inputs = np.zeros(self.max_seq_length, dtype=np.int32)
            chosen_inputs[:len(chosen_full_tokens)] = chosen_full_tokens
            
            chosen_targets = np.zeros(self.max_seq_length, dtype=np.int32)
            if len(chosen_full_tokens) > 0:
                chosen_targets[:len(chosen_full_tokens)-1] = chosen_full_tokens[1:]
                chosen_targets[len(chosen_full_tokens)-1] = self.vocab.sp.PieceToId('<eos>')

            # åˆ›å»ºæŸå¤±æ©ç  (åªåœ¨ completion éƒ¨åˆ†è®¡ç®—æŸå¤±)
            chosen_loss_mask = np.zeros(self.max_seq_length, dtype=np.float32)
            # æŸå¤±ä» prompt çš„æœ€åä¸€ä¸ª token å¼€å§‹è®¡ç®—ï¼Œå› ä¸ºå®ƒé¢„æµ‹çš„æ˜¯ completion çš„ç¬¬ä¸€ä¸ª token
            start_index = prompt_len - 1
            end_index = len(chosen_full_tokens) - 1
            if start_index < end_index:
                chosen_loss_mask[start_index:end_index] = 1.0

            # --- å¤„ç† rejected ---
            rejected_completion_tokens = self.vocab.encode(rejected_text)
            rejected_full_tokens = (prompt_tokens + rejected_completion_tokens)[:self.max_seq_length]

            rejected_inputs = np.zeros(self.max_seq_length, dtype=np.int32)
            rejected_inputs[:len(rejected_full_tokens)] = rejected_full_tokens
            
            rejected_targets = np.zeros(self.max_seq_length, dtype=np.int32)
            if len(rejected_full_tokens) > 0:
                rejected_targets[:len(rejected_full_tokens)-1] = rejected_full_tokens[1:]
                rejected_targets[len(rejected_full_tokens)-1] = self.vocab.sp.PieceToId('<eos>')

            # ä¸º rejected åˆ›å»ºæŸå¤±æ©ç 
            rejected_loss_mask = np.zeros(self.max_seq_length, dtype=np.float32)
            end_index_rej = len(rejected_full_tokens) - 1
            if start_index < end_index_rej:
                rejected_loss_mask[start_index:end_index_rej] = 1.0
            
            batch_data['chosen_inputs'].append(chosen_inputs)
            batch_data['chosen_targets'].append(chosen_targets)
            batch_data['chosen_loss_mask'].append(chosen_loss_mask)
            batch_data['rejected_inputs'].append(rejected_inputs)
            batch_data['rejected_targets'].append(rejected_targets)
            batch_data['rejected_loss_mask'].append(rejected_loss_mask)
        
        chosen_inputs = jnp.array(batch_data['chosen_inputs'], dtype=jnp.int32)
        chosen_targets = jnp.array(batch_data['chosen_targets'], dtype=jnp.int32)
        chosen_loss_mask = jnp.array(batch_data['chosen_loss_mask'], dtype=jnp.float32)
        rejected_inputs = jnp.array(batch_data['rejected_inputs'], dtype=jnp.int32)
        rejected_targets = jnp.array(batch_data['rejected_targets'], dtype=jnp.int32)
        rejected_loss_mask = jnp.array(batch_data['rejected_loss_mask'], dtype=jnp.float32)
        
        # ç¡®ä¿æ‰¹æ¬¡ç»´åº¦æ­£ç¡®
        if len(chosen_inputs.shape) != 2 or len(chosen_targets.shape) != 2:
            raise ValueError(f"æ‰¹æ¬¡ç»´åº¦é”™è¯¯: chosen_inputs shape={chosen_inputs.shape}, chosen_targets shape={chosen_targets.shape}")
        
        chosen_inputs_dict = {
            "targets": chosen_inputs,
            "start_of_sequence": jnp.ones((chosen_inputs.shape[0],), dtype=jnp.bool_)
        }
        rejected_inputs_dict = {
            "targets": rejected_inputs,
            "start_of_sequence": jnp.ones((rejected_inputs.shape[0],), dtype=jnp.bool_)
        }
        
        return (chosen_inputs_dict, chosen_targets, chosen_loss_mask), (rejected_inputs_dict, rejected_targets, rejected_loss_mask)
    
    
    def train(self, train_data: List[Dict], output_dir: str = None) -> str:
        \"\"\"è®­ç»ƒä¸»å¾ªç¯\"\"\"
        output_dir = output_dir or FLAGS.output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # è®¾ç½®è®­ç»ƒæ—¥å¿—
        log_file = os.path.join(output_dir, "dpo_training.log")
        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s: %(message)s'))
        logger.addHandler(file_handler)
        
        try:
            for epoch in range(FLAGS.num_epochs):
                random.shuffle(train_data)
                epoch_losses = []
                
                with tqdm(total=min(FLAGS.steps_per_epoch, len(train_data)//FLAGS.batch_size), 
                        desc=f"Epoch {epoch+1}") as pbar:
                    for step in range(FLAGS.steps_per_epoch):
                        try:
                            # å‡†å¤‡æ‰¹æ¬¡æ•°æ®
                            batch_examples = train_data[step*FLAGS.batch_size: (step+1)*FLAGS.batch_size]
                            if not batch_examples:
                                break
                            
                            logger.info(f"Step {step}: å‡†å¤‡æ‰¹æ¬¡æ•°æ®ï¼Œæ ·æœ¬æ•°é‡: {len(batch_examples)}")
                            chosen_data, rejected_data = self._prepare_batch(batch_examples)
                            
                            # logger.info(f"Step {step}: chosen_dataç±»å‹: {type(chosen_data)}, é•¿åº¦: {len(chosen_data)}")
                            # logger.info(f"Step {step}: rejected_dataç±»å‹: {type(rejected_data)}, é•¿åº¦: {len(rejected_data)}")
                            # logger.info(f"Step {step}: æ‰§è¡Œæ›´æ–°æ­¥éª¤")
                            loss = self._update_step(chosen_data, rejected_data)
                            epoch_losses.append(loss)
                            avg_loss = sum(epoch_losses) / len(epoch_losses)
                            
                            pbar.update(1)
                            pbar.set_postfix({'loss': f"{avg_loss:.4f}"})
                            
                            # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
                            if step > 0 and step % FLAGS.save_steps == 0:
                                self.save_checkpoint(output_dir)
                                
                        except Exception as e:
                            logger.error(f"Step {step} å¤±è´¥: {str(e)}")
                            import traceback
                            logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                            raise
                
                logger.info(f"Epoch {epoch+1} å®Œæˆ, å¹³å‡æŸå¤±: {avg_loss:.4f}")
            
            self.save_checkpoint(output_dir, final=True)
            logger.info(f"è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜åœ¨: {output_dir}")
            return output_dir
        except Exception as e:
            logger.exception(f"è®­ç»ƒå¤±è´¥: {str(e)}")
            raise
        finally:
            logger.removeHandler(file_handler)

    def save_checkpoint(self, output_dir: str, final: bool = False) -> str:
        save_name = "final_model" if final else f"checkpoint_{self.global_step}"
        save_path = os.path.join(output_dir, save_name)
        os.makedirs(save_path, exist_ok=True)
        save_flax_ckpt(
            save_dir=save_path,
            step=self.global_step,
            params=self.tstate.params,
            model_state=self.model_state,
            opt_state=self.tstate.opt_state
        )
        import json
        metadata = {
            'global_step': self.global_step,
            'vocab_path': os.path.abspath(FLAGS.vocab_path),
            'beta': self.beta
        }
        with open(os.path.join(save_path, 'metadata.json'), 'w') as f:
            json.dump(metadata, f)
        logger.info(f"æ£€æŸ¥ç‚¹ä¿å­˜è‡³: {save_path}")

        # === æ–°å¢ï¼šå¯¼å‡ºå‚æ•°ä¸º npz å’Œ pkl ===
        import numpy as np
        import pickle

        def flatten_dict(d, parent_key='', sep='/'):
            """é€’å½’å±•å¼€åµŒå¥—dictä¸ºæ‰å¹³dictï¼Œä¾¿äºnpzä¿å­˜"""
            items = []
            for k, v in d.items():
                new_key = parent_key + sep + k if parent_key else k
                if isinstance(v, dict):
                    items.extend(flatten_dict(v, new_key, sep=sep).items())
                else:
                    items.append((new_key, v))
            return dict(items)

        # å¯¼å‡ºä¸º npz
        try:
            flat_params = flatten_dict(self.tstate.params)
            npz_path = os.path.join(save_path, "params.npz")
            np.savez(npz_path, **flat_params)
            logger.info(f"å‚æ•°å·²å¯¼å‡ºä¸º npz: {npz_path}")
        except Exception as e:
            logger.warning(f"å¯¼å‡º npz å¤±è´¥: {e}")

        # å¯¼å‡ºä¸º pklï¼ˆä¿ç•™åŸå§‹åµŒå¥—ç»“æ„ï¼‰
        try:
            pkl_path = os.path.join(save_path, "params.pkl")
            with open(pkl_path, "wb") as f:
                pickle.dump(self.tstate.params, f)
            logger.info(f"å‚æ•°å·²å¯¼å‡ºä¸º pkl: {pkl_path}")
        except Exception as e:
            logger.warning(f"å¯¼å‡º pkl å¤±è´¥: {e}")

        return save_path

def load_and_validate_data(file_path: str) -> List[Dict]:
    \"\"\"åŠ è½½å’ŒéªŒè¯è®­ç»ƒæ•°æ®\"\"\"
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    valid_data = []
    score_issues = 0
    with open(file_path) as f:
        for line in f:
            if not line.strip():
                continue
                
            try:
                ex = json.loads(line)
                if 'prompt' in ex and 'chosen' in ex and 'rejected' in ex:
                    
                    # æ‰“å°æ•°æ®æ ·æœ¬
                    # logger.info(f"åŠ è½½æ•°æ®æ ·æœ¬:")
                    # logger.info(f"  prompt: {ex['prompt'][:100]}...")
                    # logger.info(f"  chosen: {ex['chosen'][:100]}...")
                    # logger.info(f"  rejected: {ex['rejected'][:100]}...")
                    # logger.info(f"  chosen_score: {ex['chosen_score']}")
                    # logger.info(f"  rejected_score: {ex['rejected_score']}")
                    
                    valid_data.append(ex)
            except json.JSONDecodeError as e:
                logger.error(f"JSONè§£æé”™è¯¯: {str(e)}")
                continue
            except Exception as e:
                logger.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                continue
    
    logger.info(f"æ•°æ®åŠ è½½å®Œæˆ: æœ‰æ•ˆæ ·æœ¬={len(valid_data)}")
    return valid_data

def main(argv):

    \"\"\"ä¸»å‡½æ•°å…¥å£\"\"\"
    try:
        os.makedirs(FLAGS.output_dir, exist_ok=True)
        logger.info(f"è¾“å‡ºç›®å½•: {FLAGS.output_dir}")
        
        trainer = DPOTrainer(
            model_path=FLAGS.ckpt_path,
            vocab_path=FLAGS.vocab_path,
            beta=FLAGS.beta,
            learning_rate=FLAGS.learning_rate,
            batch_size=FLAGS.batch_size,
            max_seq_length=FLAGS.max_seq_length,
            use_amp=FLAGS.use_amp
        )
        
        logger.info(f"å¼€å§‹åŠ è½½è®­ç»ƒæ•°æ®: {FLAGS.train_data}")
        train_data = load_and_validate_data(FLAGS.train_data)
        
        if not train_data:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
            
        logger.info(f"æˆåŠŸåŠ è½½ {len(train_data)} æ¡è®­ç»ƒæ•°æ®")
        
        logger.info("å¼€å§‹DPOè®­ç»ƒ")
        output_dir = trainer.train(train_data)
        
        logger.info(f"è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹ä¿å­˜åœ¨: {output_dir}")
        return 0
    except Exception as e:
        logger.exception(f"è®­ç»ƒè¿‡ç¨‹å¤±è´¥: {str(e)}")
        return 1

if __name__ == '__main__':
    app.run(main)